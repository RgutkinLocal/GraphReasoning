{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed20fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_reasoning_colab.ipynb (Python code cells below are meant for notebook)\n",
    "\n",
    "# Step 1: Install Required Packages\n",
    "!pip install networkx huggingface_hub pandas numpy scikit-learn transformers accelerate\n",
    "\n",
    "# Step 2: Import Libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Step 3: Load the Graph\n",
    "repo_id = 'lamm-mit/bio-graph-1K'\n",
    "graph_file = hf_hub_download(repo_id=repo_id, filename='large_graph_simple_giant.graphml')\n",
    "G = nx.read_graphml(graph_file)\n",
    "print(f\"Graph loaded with {len(G.nodes())} nodes and {len(G.edges())} edges.\")\n",
    "\n",
    "# Step 4: Load the Embeddings and Flatten\n",
    "embedding_file = hf_hub_download(repo_id=repo_id, filename='embeddings_simple_giant_ge-large-en-v1.5.pkl')\n",
    "with open(embedding_file, 'rb') as f:\n",
    "    raw_embeddings = pickle.load(f)\n",
    "\n",
    "# Flatten all embeddings to ensure correct shape\n",
    "embeddings = {k: np.array(v).squeeze() for k, v in raw_embeddings.items()}\n",
    "example_key = list(embeddings.keys())[0]\n",
    "print(f\"Sample embedding shape: {embeddings[example_key].shape}\")\n",
    "\n",
    "# Step 5: Node Similarity Function\n",
    "def get_similar_nodes(node_id, top_k=5):\n",
    "    if node_id not in embeddings:\n",
    "        return []\n",
    "    vec = embeddings[node_id].squeeze().reshape(1, -1)\n",
    "    keys = list(embeddings.keys())\n",
    "    mat = np.stack([embeddings[k] for k in keys])\n",
    "    sims = cosine_similarity(vec, mat)[0]\n",
    "    top_indices = np.argsort(-sims)[1:top_k+1]\n",
    "    return [(keys[i], sims[i]) for i in top_indices]\n",
    "\n",
    "# Step 6: Shortest Path Finder\n",
    "def find_path(start_node, end_node):\n",
    "    if start_node not in G or end_node not in G:\n",
    "        return \"Invalid node(s)\"\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source=start_node, target=end_node)\n",
    "        return path\n",
    "    except nx.NetworkXNoPath:\n",
    "        return \"No path found\"\n",
    "\n",
    "# Step 7: Open-Source Reasoning with Mistral\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def query_local_model(prompt, max_tokens=200):\n",
    "    output = pipe(prompt, max_new_tokens=max_tokens, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
    "    return output\n",
    "\n",
    "# Example Use\n",
    "# path = find_path(\"mineralized collagen fibers\", \"schreger pattern\")\n",
    "# print(path)\n",
    "\n",
    "# similar_nodes = get_similar_nodes(\"hydroxyapatite\")\n",
    "# print(similar_nodes)\n",
    "\n",
    "# prompt = \"How is mineralized collagen structurally similar to nacre?\"\n",
    "# print(query_local_model(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf00d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
